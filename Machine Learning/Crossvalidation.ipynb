{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267e5c44-4a63-4e3f-91da-cf91e300c387",
   "metadata": {},
   "source": [
    "# Cross-Validation in Machine Learning\n",
    "\n",
    "Cross-validation is a powerful technique used to evaluate the performance of a machine learning model.  \n",
    "Instead of relying on just one train-test split, cross-validation uses **multiple splits** of the dataset, making the evaluation more **robust and reliable**.\n",
    "\n",
    "In this notebook, we will cover:\n",
    "1. Why Cross-Validation is needed  \n",
    "2. Different types of Cross-Validation  \n",
    "3. Practical implementation in Python (Scikit-learn)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06e8c6f-4dab-4593-9230-d32087c4ccec",
   "metadata": {},
   "source": [
    "## Why Do We Need Cross-Validation?\n",
    "\n",
    "- When we split data into **train (80%) and test (20%)**, the result depends heavily on **how the split is made**.  \n",
    "- Maybe the test set is too easy or too difficult â†’ performance is misleading.  \n",
    "- We want to check **how well our model generalizes** to unseen data.  \n",
    "\n",
    "ðŸ‘‰ Cross-validation solves this problem by evaluating the model on **multiple different splits** and then taking the average score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7458ce-f74a-4b94-90ed-332adc828406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e311d67a-a0a2-469d-9eb5-deccbe96bff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (150, 4)\n",
      "Shape of y: (150,)\n"
     ]
    }
   ],
   "source": [
    "# Load a sample dataset (Iris dataset)\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33f517-9963-42bc-bc28-6b8b72efd1c5",
   "metadata": {},
   "source": [
    "## Limitation of Single Train-Test Split\n",
    "\n",
    "If we do only one split (say 80â€“20), the evaluation depends on which data points end up in training and testing.  \n",
    "This can lead to **biased or unstable results**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd0d1c6-ea52-4411-aef9-e05eeae29a3c",
   "metadata": {},
   "source": [
    "## K-Fold Cross-Validation\n",
    "\n",
    "- Dataset is divided into **K folds** (subsets).  \n",
    "- Each time, one fold is used as the test set and the remaining **K-1 folds** are used for training.  \n",
    "- Process is repeated K times, and performance is averaged.  \n",
    "\n",
    "Example: In **5-Fold CV**, dataset is split into 5 parts.  \n",
    "The model is trained and tested 5 times, each time with a different test fold.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ed5cea-c1e4-46b9-844f-b77a61335510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96666667 0.96666667 0.9        1.         1.        ]\n",
      "Average CV Score: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "# Apply 5-Fold Cross Validation\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average CV Score:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f89ef5-fb70-4808-96e4-d8fbd02d6f8b",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Cross-Validation\n",
    "\n",
    "- In classification, if classes are imbalanced, normal K-Fold may create folds with **unequal class distribution**.  \n",
    "- **Stratified K-Fold** ensures that each fold has the same **class proportion** as the overall dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "566486ca-d378-480c-aaf3-ea492cfb5ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-Fold CV scores: [0.96666667 0.96666667 0.9        1.         1.        ]\n",
      "Average Stratified CV Score: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-Fold ensures class balance in each fold\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=skf)\n",
    "\n",
    "print(\"Stratified K-Fold CV scores:\", scores)\n",
    "print(\"Average Stratified CV Score:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7446410c-5135-4c71-bc53-eb5a10e285ea",
   "metadata": {},
   "source": [
    "## Leave-One-Out Cross-Validation (LOOCV)\n",
    "\n",
    "- Extreme case of K-Fold CV â†’ where **K = number of samples**.  \n",
    "- Each time, **1 sample** is used for testing, and the rest for training.  \n",
    "- Very accurate, but computationally expensive for large datasets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd3eb14-cbb7-4c04-97f1-0269d6f777f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 150\n",
      "Average LOOCV Score: 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(model, X, y, cv=loo)\n",
    "\n",
    "print(\"Number of iterations:\", len(scores))\n",
    "print(\"Average LOOCV Score:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725ea77-63c5-42a4-ab4e-dd12940f4c33",
   "metadata": {},
   "source": [
    "## Time Series Cross-Validation\n",
    "\n",
    "- For time series, we **cannot shuffle data** (since order matters).  \n",
    "- Use **forward chaining**:\n",
    "  - Train on data up to time `t`, test on time `t+1`.  \n",
    "  - Expand training set step by step.  \n",
    "\n",
    "Scikit-learn provides `TimeSeriesSplit` for this purpose.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b778da-aa02-4a9f-a278-1112244562ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24] Test: [25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49]\n",
      "Train: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49] Test: [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74]\n",
      "Train: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74] Test: [75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98\n",
      " 99]\n",
      "Train: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] Test: [100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124]\n",
      "Train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124] Test: [125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8517ad-8eaf-4fb6-af9a-1a87ceb5ab3d",
   "metadata": {},
   "source": [
    "#  Conclusion\n",
    "\n",
    "- **Cross-validation** is a reliable method to evaluate models.  \n",
    "- **K-Fold CV (k=5 or 10)** is most commonly used.  \n",
    "- **Stratified K-Fold** is better for classification with imbalanced data.  \n",
    "- **LOOCV** gives accurate results but is slow.  \n",
    "- **Time Series CV** is best when order matters.  \n",
    "\n",
    "ðŸ‘‰ Always combine **cross-validation with hyperparameter tuning** for best performance.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
